{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [02_BTB0.63523evaluation](https://www.kaggle.com/clustifier/btb-0-63523-evaluation/code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 understand apk & mapk\n",
    "- [code](https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py)\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])\n",
    "```\n",
    "\n",
    "- summary\n",
    "\n",
    "```\n",
    "    1. If acutual list has zero elements, then always return 1;\n",
    "    2. If actual list has more than one elements, then the order of actual list doesn't matter; The final value will be avg of several single prediction results;\n",
    "    3. If acutual list is not None, then the order of prediction list matters; \n",
    "    4. If max number is given, the predicted result will be shorten to len of max number.\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero elements\n",
      "1.0\n",
      "1.0\n",
      "several elements\n",
      "0.5\n",
      "0.5833333333333333\n",
      "0.5833333333333333\n",
      "0.6791666666666667\n",
      "1.0\n",
      "order matter\n",
      "1.0\n",
      "0.5\n",
      "0.3333333333333333\n",
      "0.25\n",
      "max number\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from ml_metrics import apk\n",
    "\n",
    "print(\"zero elements\")\n",
    "print(apk([],[]))\n",
    "print(apk([],[1,2]))\n",
    "print(\"several elements\")\n",
    "print(apk([1,2],[1]))\n",
    "print(apk([1,2],[10,1,2]))\n",
    "print(apk([2,1],[10,1,2]))\n",
    "print(apk([1,2,3,4],[10,1,2,3,4]))\n",
    "print(apk([1,2,3,4],[1,2,3,4]))\n",
    "print(\"order matter\")\n",
    "print(apk([1],[1,2,3,4]))\n",
    "print(apk([2],[1,2,3,4]))\n",
    "print(apk([3],[1,2,3,4]))\n",
    "print(apk([4],[1,2,3,4]))\n",
    "print(\"max number\")\n",
    "print(apk([4],[1,2,3,4],k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero elements\n",
      "0.0\n",
      "0.0\n",
      "several elements\n",
      "0.5\n",
      "0.5833333333333333\n",
      "0.5833333333333333\n",
      "0.6791666666666667\n",
      "1.0\n",
      "order matter\n",
      "1.0\n",
      "0.5\n",
      "0.3333333333333333\n",
      "0.25\n",
      "max number\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# try to rewrite the apk function\n",
    "def apk(actual,predicted,k=10):\n",
    "    if len(predicted)>k:\n",
    "        predicted=predicted[:k]    \n",
    "    if not actual:\n",
    "        return 1.0\n",
    "    num_hits=0.0\n",
    "    score=0.0\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits+=1.0\n",
    "            score+= num_hits /(i+1)\n",
    "    return score/min(len(actual),k)\n",
    "\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "            \n",
    "print(\"zero elements\")\n",
    "print(apk([],[]))\n",
    "print(apk([],[1,2]))\n",
    "print(\"several elements\")\n",
    "print(apk([1,2],[1]))\n",
    "print(apk([1,2],[10,1,2]))\n",
    "print(apk([2,1],[10,1,2]))\n",
    "print(apk([1,2,3,4],[10,1,2,3,4]))\n",
    "print(apk([1,2,3,4],[1,2,3,4]))\n",
    "print(\"order matter\")\n",
    "print(apk([1],[1,2,3,4]))\n",
    "print(apk([2],[1,2,3,4]))\n",
    "print(apk([3],[1,2,3,4]))\n",
    "print(apk([4],[1,2,3,4]))\n",
    "print(\"max number\")\n",
    "print(apk([4],[1,2,3,4],k=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "reg = 12 # trying anokas idea of regularization\n",
    "eval = True\n",
    "\n",
    "train = pd.read_csv(\"../../data/unzip_data/clicks_train.csv\")\n",
    "\n",
    "if eval:\n",
    "\tids = train.display_id.unique()\n",
    "\tids = np.random.choice(ids, size=len(ids)//10, replace=False)\n",
    "\n",
    "\tvalid = train[train.display_id.isin(ids)]\n",
    "\ttrain = train[~train.display_id.isin(ids)]\n",
    "\t\n",
    "\tprint (valid.shape, train.shape)\n",
    "\n",
    "cnt = train[train.clicked==1].ad_id.value_counts()\n",
    "cntall = train.ad_id.value_counts()\n",
    "del train\n",
    "\n",
    "def get_prob(k):\n",
    "    if k not in cnt:\n",
    "        return 0\n",
    "    return cnt[k]/(float(cntall[k]) + reg)\n",
    "\n",
    "def srt(x):\n",
    "    ad_ids = map(int, x.split())\n",
    "    ad_ids = sorted(ad_ids, key=get_prob, reverse=True)\n",
    "    return \" \".join(map(str,ad_ids))\n",
    "   \n",
    "if eval:\n",
    "\tfrom ml_metrics import mapk\n",
    "\t\n",
    "\ty = valid[valid.clicked==1].ad_id.values\n",
    "\ty = [[_] for _ in y]\n",
    "\tp = valid.groupby('display_id').ad_id.apply(list)\n",
    "\tp = [sorted(x, key=get_prob, reverse=True) for x in p]\n",
    "\t\n",
    "\tprint (mapk(y, p, k=12))\n",
    "else:\n",
    "\tsubm = pd.read_csv(\"../../data/unzip_data/sample_submission.csv\") \n",
    "\tsubm['ad_id'] = subm.ad_id.apply(lambda x: srt(x))\n",
    "\tsubm.to_csv(\"subm_reg_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Rewrite the code\n",
    "\n",
    "- It is not very efficient of the sorted method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "vaild=True\n",
    "L=12\n",
    "# NROW=-1\n",
    "\n",
    "train = pd.read_csv(\"../../data/unzip_data/clicks_train.csv\")\n",
    "cnt = train[train.clicked==1].ad_id.value_counts()\n",
    "cntall = train.ad_id.value_counts()\n",
    "M=train.clicked.mean()\n",
    "\n",
    "def get_prob(k):\n",
    "    if k not in cnt:\n",
    "        return M\n",
    "    return (L+cnt[k])/(cntall[k]+L)\n",
    "\n",
    "def srt(x):\n",
    "    ad_ids=map(int,x.split())\n",
    "    ad_ids=sorted(ad_ids,key=get_prob,reverse=True)\n",
    "    return \" \".join(map(str,ad_ids))\n",
    "        \n",
    "subm = pd.read_csv(\"../../data/unzip_data/sample_submission.csv\") \n",
    "subm['ad_id'] = subm.ad_id.apply(lambda x: srt(x))\n",
    "subm.to_csv(\"subm_reg.csv\".format(L), index=False)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Outbrain Click Prediction"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kaggle competitions submit -c outbrain-click-prediction -f subm_reg.csv -m \"BTB0.63523evaluation https://www.kaggle.com/clustifier/btb-0-63523-evaluation/code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
